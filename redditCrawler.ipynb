{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "409b2c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in c:\\users\\s\\anaconda3\\lib\\site-packages (7.7.0)\n",
      "Requirement already satisfied: update-checker>=0.18 in c:\\users\\s\\anaconda3\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in c:\\users\\s\\anaconda3\\lib\\site-packages (from praw) (2.3.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\s\\anaconda3\\lib\\site-packages (from praw) (1.5.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\s\\anaconda3\\lib\\site-packages (from prawcore<3,>=2.1->praw) (2.30.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\s\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\s\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\s\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\s\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3d27234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S\\AppData\\Local\\Temp/ipykernel_14708/1029290992.py:33: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  for submission in reddit.subreddit(subreddit_name).top(time_period, limit=5000):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to travel.csv\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Define your Reddit API credentials\n",
    "client_id = 'xL9gKzqj3JAiEFr974cyTQ'\n",
    "client_secret = 'povvpq4amoxD5aHjl52pOXhVVbilQg'\n",
    "user_agent = 'Travel 2.1 by /u/ DapperWitness6024'\n",
    "username = 'Enter_Username'\n",
    "password = 'Enter_Password'\n",
    "\n",
    "# Authenticate with the Reddit API\n",
    "reddit = praw.Reddit(client_id=client_id,\n",
    "                     client_secret=client_secret,\n",
    "                     user_agent=user_agent,\n",
    "                     username=username,\n",
    "                     password=password)\n",
    "\n",
    "# Define the subreddit you want to crawl\n",
    "subreddit_name = 'Travel'\n",
    "\n",
    "# Define the time period of data collection (in days)\n",
    "time_period = \"year\"\n",
    "\n",
    "# Define the geographic location of your target audience (optional)\n",
    "# Example: target_location = 'unitedkingdom'\n",
    "target_location = None\n",
    "\n",
    "# Define a list to store the results\n",
    "results = []\n",
    "\n",
    "# Get the top posts from the subreddit\n",
    "for submission in reddit.subreddit(subreddit_name).top(time_period, limit=5000):\n",
    "    # Check if the post is from the target location (if specified)\n",
    "    if target_location and target_location.lower() not in submission.title.lower():\n",
    "        continue\n",
    "    \n",
    "    # Convert created_utc to datetime\n",
    "    created_date = datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Collect metadata for each post\n",
    "    metadata = {\n",
    "        'title': submission.title,\n",
    "        'score': submission.score,\n",
    "        'author': submission.author.name if submission.author else 'Unknown',\n",
    "        'created_date': created_date,\n",
    "        'url': submission.url,\n",
    "        'num_comments': submission.num_comments\n",
    "        # Add more metadata fields as needed\n",
    "    }\n",
    "    \n",
    "    # Store the metadata in the results list\n",
    "    results.append(metadata)\n",
    "\n",
    "# Save the results into a CSV file\n",
    "with open('travel.csv', 'w', encoding='utf-8', newline='') as file:\n",
    "    fieldnames = ['title', 'score', 'author', 'created_date', 'url', 'num_comments']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "print('Results saved to travel.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "002cc181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S\\AppData\\Local\\Temp/ipykernel_14708/4123919886.py:33: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  for submission in reddit.subreddit(subreddit_name).top(time_period, limit=5000):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to solotravel.csv\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Define your Reddit API credentials\n",
    "client_id = 'xL9gKzqj3JAiEFr974cyTQ'\n",
    "client_secret = 'povvpq4amoxD5aHjl52pOXhVVbilQg'\n",
    "user_agent = 'Travel 2.1 by /u/ DapperWitness6024'\n",
    "username = 'Enter_Username'\n",
    "password = 'Enter_Password'\n",
    "\n",
    "# Authenticate with the Reddit API\n",
    "reddit = praw.Reddit(client_id=client_id,\n",
    "                     client_secret=client_secret,\n",
    "                     user_agent=user_agent,\n",
    "                     username=username,\n",
    "                     password=password)\n",
    "\n",
    "# Define the subreddit you want to crawl\n",
    "subreddit_name = 'solotravel'\n",
    "\n",
    "# Define the time period of data collection (in days)\n",
    "time_period = \"year\"\n",
    "\n",
    "# Define the geographic location of your target audience (optional)\n",
    "# Example: target_location = 'unitedkingdom'\n",
    "target_location = None\n",
    "\n",
    "# Define a list to store the results\n",
    "results = []\n",
    "\n",
    "# Get the top posts from the subreddit\n",
    "for submission in reddit.subreddit(subreddit_name).top(time_period, limit=5000):\n",
    "    # Check if the post is from the target location (if specified)\n",
    "    if target_location and target_location.lower() not in submission.title.lower():\n",
    "        continue\n",
    "    \n",
    "    # Convert created_utc to datetime\n",
    "    created_date = datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Collect metadata for each post\n",
    "    metadata = {\n",
    "        'title': submission.title,\n",
    "        'score': submission.score,\n",
    "        'author': submission.author.name if submission.author else 'Unknown',\n",
    "        'created_date': created_date,\n",
    "        'url': submission.url,\n",
    "        'num_comments': submission.num_comments\n",
    "        # Add more metadata fields as needed\n",
    "    }\n",
    "    \n",
    "    # Store the metadata in the results list\n",
    "    results.append(metadata)\n",
    "\n",
    "# Save the results into a CSV file\n",
    "with open('solotravel.csv', 'w', encoding='utf-8', newline='') as file:\n",
    "    fieldnames = ['title', 'score', 'author', 'created_date', 'url', 'num_comments']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "print('Results saved to solotravel.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f026e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S\\AppData\\Local\\Temp/ipykernel_14708/1825329157.py:33: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  for submission in reddit.subreddit(subreddit_name).top(time_period, limit=5000):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to traveldeals.csv\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Define your Reddit API credentials\n",
    "client_id = 'xL9gKzqj3JAiEFr974cyTQ'\n",
    "client_secret = 'povvpq4amoxD5aHjl52pOXhVVbilQg'\n",
    "user_agent = 'Travel 2.1 by /u/ DapperWitness6024'\n",
    "username = 'Enter_Username'\n",
    "password = 'Enter_Password'\n",
    "\n",
    "# Authenticate with the Reddit API\n",
    "reddit = praw.Reddit(client_id=client_id,\n",
    "                     client_secret=client_secret,\n",
    "                     user_agent=user_agent,\n",
    "                     username=username,\n",
    "                     password=password)\n",
    "\n",
    "# Define the subreddit you want to crawl\n",
    "subreddit_name = 'traveldeals'\n",
    "\n",
    "# Define the time period of data collection (in days)\n",
    "time_period = \"year\"\n",
    "\n",
    "# Define the geographic location of your target audience (optional)\n",
    "# Example: target_location = 'unitedkingdom'\n",
    "target_location = None\n",
    "\n",
    "# Define a list to store the results\n",
    "results = []\n",
    "\n",
    "# Get the top posts from the subreddit\n",
    "for submission in reddit.subreddit(subreddit_name).top(time_period, limit=5000):\n",
    "    # Check if the post is from the target location (if specified)\n",
    "    if target_location and target_location.lower() not in submission.title.lower():\n",
    "        continue\n",
    "    \n",
    "    # Convert created_utc to datetime\n",
    "    created_date = datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Collect metadata for each post\n",
    "    metadata = {\n",
    "        'title': submission.title,\n",
    "        'score': submission.score,\n",
    "        'author': submission.author.name if submission.author else 'Unknown',\n",
    "        'created_date': created_date,\n",
    "        'url': submission.url,\n",
    "        'num_comments': submission.num_comments\n",
    "        # Add more metadata fields as needed\n",
    "    }\n",
    "    \n",
    "    # Store the metadata in the results list\n",
    "    results.append(metadata)\n",
    "\n",
    "# Save the results into a CSV file\n",
    "with open('traveldeals.csv', 'w', encoding='utf-8', newline='') as file:\n",
    "    fieldnames = ['title', 'score', 'author', 'created_date', 'url', 'num_comments']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "print('Results saved to traveldeals.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbabf766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S\\AppData\\Local\\Temp/ipykernel_14708/643541704.py:33: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  for submission in reddit.subreddit(subreddit_name).top(time_period, limit=5000):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to backpacking.csv\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Define your Reddit API credentials\n",
    "client_id = 'xL9gKzqj3JAiEFr974cyTQ'\n",
    "client_secret = 'povvpq4amoxD5aHjl52pOXhVVbilQg'\n",
    "user_agent = 'Travel 2.1 by /u/ DapperWitness6024'\n",
    "username = 'Enter_Username'\n",
    "password = 'Enter_Password'\n",
    "\n",
    "# Authenticate with the Reddit API\n",
    "reddit = praw.Reddit(client_id=client_id,\n",
    "                     client_secret=client_secret,\n",
    "                     user_agent=user_agent,\n",
    "                     username=username,\n",
    "                     password=password)\n",
    "\n",
    "# Define the subreddit you want to crawl\n",
    "subreddit_name = 'backpacking'\n",
    "\n",
    "# Define the time period of data collection (in days)\n",
    "time_period = \"year\"\n",
    "\n",
    "# Define the geographic location of your target audience (optional)\n",
    "# Example: target_location = 'unitedkingdom'\n",
    "target_location = None\n",
    "\n",
    "# Define a list to store the results\n",
    "results = []\n",
    "\n",
    "# Get the top posts from the subreddit\n",
    "for submission in reddit.subreddit(subreddit_name).top(time_period, limit=5000):\n",
    "    # Check if the post is from the target location (if specified)\n",
    "    if target_location and target_location.lower() not in submission.title.lower():\n",
    "        continue\n",
    "    \n",
    "    # Convert created_utc to datetime\n",
    "    created_date = datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Collect metadata for each post\n",
    "    metadata = {\n",
    "        'title': submission.title,\n",
    "        'score': submission.score,\n",
    "        'author': submission.author.name if submission.author else 'Unknown',\n",
    "        'created_date': created_date,\n",
    "        'url': submission.url,\n",
    "        'num_comments': submission.num_comments\n",
    "        # Add more metadata fields as needed\n",
    "    }\n",
    "    \n",
    "    # Store the metadata in the results list\n",
    "    results.append(metadata)\n",
    "\n",
    "# Save the results into a CSV file\n",
    "with open('backpacking.csv', 'w', encoding='utf-8', newline='') as file:\n",
    "    fieldnames = ['title', 'score', 'author', 'created_date', 'url', 'num_comments']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "print('Results saved to backpacking.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "537d332e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S\\AppData\\Local\\Temp/ipykernel_14708/2455815486.py:33: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  for submission in reddit.subreddit(subreddit_name).top(time_period, limit=5000):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to campingandhiking.csv\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Define your Reddit API credentials\n",
    "client_id = 'xL9gKzqj3JAiEFr974cyTQ'\n",
    "client_secret = 'povvpq4amoxD5aHjl52pOXhVVbilQg'\n",
    "user_agent = 'Travel 2.1 by /u/ DapperWitness6024'\n",
    "username = 'Enter_Username'\n",
    "password = 'Enter_Password'\n",
    "\n",
    "# Authenticate with the Reddit API\n",
    "reddit = praw.Reddit(client_id=client_id,\n",
    "                     client_secret=client_secret,\n",
    "                     user_agent=user_agent,\n",
    "                     username=username,\n",
    "                     password=password)\n",
    "\n",
    "# Define the subreddit you want to crawl\n",
    "subreddit_name = 'campingandhiking'\n",
    "\n",
    "# Define the time period of data collection (in days)\n",
    "time_period = \"year\"\n",
    "\n",
    "# Define the geographic location of your target audience (optional)\n",
    "# Example: target_location = 'unitedkingdom'\n",
    "target_location = None\n",
    "\n",
    "# Define a list to store the results\n",
    "results = []\n",
    "\n",
    "# Get the top posts from the subreddit\n",
    "for submission in reddit.subreddit(subreddit_name).top(time_period, limit=5000):\n",
    "    # Check if the post is from the target location (if specified)\n",
    "    if target_location and target_location.lower() not in submission.title.lower():\n",
    "        continue\n",
    "    \n",
    "    # Convert created_utc to datetime\n",
    "    created_date = datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Collect metadata for each post\n",
    "    metadata = {\n",
    "        'title': submission.title,\n",
    "        'score': submission.score,\n",
    "        'author': submission.author.name if submission.author else 'Unknown',\n",
    "        'created_date': created_date,\n",
    "        'url': submission.url,\n",
    "        'num_comments': submission.num_comments\n",
    "        # Add more metadata fields as needed\n",
    "    }\n",
    "    \n",
    "    # Store the metadata in the results list\n",
    "    results.append(metadata)\n",
    "\n",
    "# Save the results into a CSV file\n",
    "with open('campingandhiking.csv', 'w', encoding='utf-8', newline='') as file:\n",
    "    fieldnames = ['title', 'score', 'author', 'created_date', 'url', 'num_comments']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "print('Results saved to campingandhiking.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59bc3ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S\\AppData\\Local\\Temp/ipykernel_14708/3387262186.py:33: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  for submission in reddit.subreddit(subreddit_name).top(time_period, limit=5000):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to adventures.csv\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Define your Reddit API credentials\n",
    "client_id = 'xL9gKzqj3JAiEFr974cyTQ'\n",
    "client_secret = 'povvpq4amoxD5aHjl52pOXhVVbilQg'\n",
    "user_agent = 'Travel 2.1 by /u/ DapperWitness6024'\n",
    "username = 'Enter_Username'\n",
    "password = 'Enter_Password'\n",
    "\n",
    "# Authenticate with the Reddit API\n",
    "reddit = praw.Reddit(client_id=client_id,\n",
    "                     client_secret=client_secret,\n",
    "                     user_agent=user_agent,\n",
    "                     username=username,\n",
    "                     password=password)\n",
    "\n",
    "# Define the subreddit you want to crawl\n",
    "subreddit_name = 'adventures'\n",
    "\n",
    "# Define the time period of data collection (in days)\n",
    "time_period = \"year\"\n",
    "\n",
    "# Define the geographic location of your target audience (optional)\n",
    "# Example: target_location = 'unitedkingdom'\n",
    "target_location = None\n",
    "\n",
    "# Define a list to store the results\n",
    "results = []\n",
    "\n",
    "# Get the top posts from the subreddit\n",
    "for submission in reddit.subreddit(subreddit_name).top(time_period, limit=5000):\n",
    "    # Check if the post is from the target location (if specified)\n",
    "    if target_location and target_location.lower() not in submission.title.lower():\n",
    "        continue\n",
    "    \n",
    "    # Convert created_utc to datetime\n",
    "    created_date = datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Collect metadata for each post\n",
    "    metadata = {\n",
    "        'title': submission.title,\n",
    "        'score': submission.score,\n",
    "        'author': submission.author.name if submission.author else 'Unknown',\n",
    "        'created_date': created_date,\n",
    "        'url': submission.url,\n",
    "        'num_comments': submission.num_comments\n",
    "        # Add more metadata fields as needed\n",
    "    }\n",
    "    \n",
    "    # Store the metadata in the results list\n",
    "    results.append(metadata)\n",
    "\n",
    "# Save the results into a CSV file\n",
    "with open('adventures.csv', 'w', encoding='utf-8', newline='') as file:\n",
    "    fieldnames = ['title', 'score', 'author', 'created_date', 'url', 'num_comments']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "print('Results saved to adventures.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8dc0db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S\\AppData\\Local\\Temp/ipykernel_14708/3469757177.py:33: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  for submission in reddit.subreddit(subreddit_name).top(time_period, limit=5000):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to travelhacks.csv\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Define your Reddit API credentials\n",
    "client_id = 'xL9gKzqj3JAiEFr974cyTQ'\n",
    "client_secret = 'povvpq4amoxD5aHjl52pOXhVVbilQg'\n",
    "user_agent = 'Travel 2.1 by /u/ DapperWitness6024'\n",
    "username = 'Enter_Username'\n",
    "password = 'Enter_Password'\n",
    "\n",
    "# Authenticate with the Reddit API\n",
    "reddit = praw.Reddit(client_id=client_id,\n",
    "                     client_secret=client_secret,\n",
    "                     user_agent=user_agent,\n",
    "                     username=username,\n",
    "                     password=password)\n",
    "\n",
    "# Define the subreddit you want to crawl\n",
    "subreddit_name = 'travelhacks'\n",
    "\n",
    "# Define the time period of data collection (in days)\n",
    "time_period = \"year\"\n",
    "\n",
    "# Define the geographic location of your target audience (optional)\n",
    "# Example: target_location = 'unitedkingdom'\n",
    "target_location = None\n",
    "\n",
    "# Define a list to store the results\n",
    "results = []\n",
    "\n",
    "# Get the top posts from the subreddit\n",
    "for submission in reddit.subreddit(subreddit_name).top(time_period, limit=5000):\n",
    "    # Check if the post is from the target location (if specified)\n",
    "    if target_location and target_location.lower() not in submission.title.lower():\n",
    "        continue\n",
    "    \n",
    "    # Convert created_utc to datetime\n",
    "    created_date = datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Collect metadata for each post\n",
    "    metadata = {\n",
    "        'title': submission.title,\n",
    "        'score': submission.score,\n",
    "        'author': submission.author.name if submission.author else 'Unknown',\n",
    "        'created_date': created_date,\n",
    "        'url': submission.url,\n",
    "        'num_comments': submission.num_comments\n",
    "        # Add more metadata fields as needed\n",
    "    }\n",
    "    \n",
    "    # Store the metadata in the results list\n",
    "    results.append(metadata)\n",
    "\n",
    "# Save the results into a CSV file\n",
    "with open('travelhacks.csv', 'w', encoding='utf-8', newline='') as file:\n",
    "    fieldnames = ['title', 'score', 'author', 'created_date', 'url', 'num_comments']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "print('Results saved to travelhacks.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e71a047d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S\\AppData\\Local\\Temp/ipykernel_14708/2398314430.py:33: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  for submission in reddit.subreddit(subreddit_name).top(time_period, limit=5000):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to roadtrip.csv\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Define your Reddit API credentials\n",
    "client_id = 'xL9gKzqj3JAiEFr974cyTQ'\n",
    "client_secret = 'povvpq4amoxD5aHjl52pOXhVVbilQg'\n",
    "user_agent = 'Travel 2.1 by /u/ DapperWitness6024'\n",
    "username = 'Enter_Username'\n",
    "password = 'Enter_Password'\n",
    "\n",
    "# Authenticate with the Reddit API\n",
    "reddit = praw.Reddit(client_id=client_id,\n",
    "                     client_secret=client_secret,\n",
    "                     user_agent=user_agent,\n",
    "                     username=username,\n",
    "                     password=password)\n",
    "\n",
    "# Define the subreddit you want to crawl\n",
    "subreddit_name = 'roadtrip'\n",
    "\n",
    "# Define the time period of data collection (in days)\n",
    "time_period = \"year\"\n",
    "\n",
    "# Define the geographic location of your target audience (optional)\n",
    "# Example: target_location = 'unitedkingdom'\n",
    "target_location = None\n",
    "\n",
    "# Define a list to store the results\n",
    "results = []\n",
    "\n",
    "# Get the top posts from the subreddit\n",
    "for submission in reddit.subreddit(subreddit_name).top(time_period, limit=5000):\n",
    "    # Check if the post is from the target location (if specified)\n",
    "    if target_location and target_location.lower() not in submission.title.lower():\n",
    "        continue\n",
    "    \n",
    "    # Convert created_utc to datetime\n",
    "    created_date = datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Collect metadata for each post\n",
    "    metadata = {\n",
    "        'title': submission.title,\n",
    "        'score': submission.score,\n",
    "        'author': submission.author.name if submission.author else 'Unknown',\n",
    "        'created_date': created_date,\n",
    "        'url': submission.url,\n",
    "        'num_comments': submission.num_comments\n",
    "        # Add more metadata fields as needed\n",
    "    }\n",
    "    \n",
    "    # Store the metadata in the results list\n",
    "    results.append(metadata)\n",
    "\n",
    "# Save the results into a CSV file\n",
    "with open('roadtrip.csv', 'w', encoding='utf-8', newline='') as file:\n",
    "    fieldnames = ['title', 'score', 'author', 'created_date', 'url', 'num_comments']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "print('Results saved to roadtrip.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d40b52de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S\\AppData\\Local\\Temp/ipykernel_14708/2237827337.py:33: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  for submission in reddit.subreddit(subreddit_name).top(time_period, limit=5000):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to airbnb.csv\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Define your Reddit API credentials\n",
    "client_id = 'xL9gKzqj3JAiEFr974cyTQ'\n",
    "client_secret = 'povvpq4amoxD5aHjl52pOXhVVbilQg'\n",
    "user_agent = 'Travel 2.1 by /u/ DapperWitness6024'\n",
    "username = 'Enter_Username'\n",
    "password = 'Enter_Password'\n",
    "\n",
    "# Authenticate with the Reddit API\n",
    "reddit = praw.Reddit(client_id=client_id,\n",
    "                     client_secret=client_secret,\n",
    "                     user_agent=user_agent,\n",
    "                     username=username,\n",
    "                     password=password)\n",
    "\n",
    "# Define the subreddit you want to crawl\n",
    "subreddit_name = 'airbnb'\n",
    "\n",
    "# Define the time period of data collection (in days)\n",
    "time_period = \"year\"\n",
    "\n",
    "# Define the geographic location of your target audience (optional)\n",
    "# Example: target_location = 'unitedkingdom'\n",
    "target_location = None\n",
    "\n",
    "# Define a list to store the results\n",
    "results = []\n",
    "\n",
    "# Get the top posts from the subreddit\n",
    "for submission in reddit.subreddit(subreddit_name).top(time_period, limit=5000):\n",
    "    # Check if the post is from the target location (if specified)\n",
    "    if target_location and target_location.lower() not in submission.title.lower():\n",
    "        continue\n",
    "    \n",
    "    # Convert created_utc to datetime\n",
    "    created_date = datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Collect metadata for each post\n",
    "    metadata = {\n",
    "        'title': submission.title,\n",
    "        'score': submission.score,\n",
    "        'author': submission.author.name if submission.author else 'Unknown',\n",
    "        'created_date': created_date,\n",
    "        'url': submission.url,\n",
    "        'num_comments': submission.num_comments\n",
    "        # Add more metadata fields as needed\n",
    "    }\n",
    "    \n",
    "    # Store the metadata in the results list\n",
    "    results.append(metadata)\n",
    "\n",
    "# Save the results into a CSV file\n",
    "with open('airbnb.csv', 'w', encoding='utf-8', newline='') as file:\n",
    "    fieldnames = ['title', 'score', 'author', 'created_date', 'url', 'num_comments']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "print('Results saved to airbnb.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8940b787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S\\AppData\\Local\\Temp/ipykernel_14708/2995163755.py:33: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  for submission in reddit.subreddit(subreddit_name).top(time_period, limit=5000):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to travelphotos.csv\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Define your Reddit API credentials\n",
    "client_id = 'xL9gKzqj3JAiEFr974cyTQ'\n",
    "client_secret = 'povvpq4amoxD5aHjl52pOXhVVbilQg'\n",
    "user_agent = 'Travel 2.1 by /u/ DapperWitness6024'\n",
    "username = 'Enter_Username'\n",
    "password = 'Enter_Password'\n",
    "\n",
    "# Authenticate with the Reddit API\n",
    "reddit = praw.Reddit(client_id=client_id,\n",
    "                     client_secret=client_secret,\n",
    "                     user_agent=user_agent,\n",
    "                     username=username,\n",
    "                     password=password)\n",
    "\n",
    "# Define the subreddit you want to crawl\n",
    "subreddit_name = 'travelphotos'\n",
    "\n",
    "# Define the time period of data collection (in days)\n",
    "time_period = \"year\"\n",
    "\n",
    "# Define the geographic location of your target audience (optional)\n",
    "# Example: target_location = 'unitedkingdom'\n",
    "target_location = None\n",
    "\n",
    "# Define a list to store the results\n",
    "results = []\n",
    "\n",
    "# Get the top posts from the subreddit\n",
    "for submission in reddit.subreddit(subreddit_name).top(time_period, limit=5000):\n",
    "    # Check if the post is from the target location (if specified)\n",
    "    if target_location and target_location.lower() not in submission.title.lower():\n",
    "        continue\n",
    "    \n",
    "    # Convert created_utc to datetime\n",
    "    created_date = datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Collect metadata for each post\n",
    "    metadata = {\n",
    "        'title': submission.title,\n",
    "        'score': submission.score,\n",
    "        'author': submission.author.name if submission.author else 'Unknown',\n",
    "        'created_date': created_date,\n",
    "        'url': submission.url,\n",
    "        'num_comments': submission.num_comments\n",
    "        # Add more metadata fields as needed\n",
    "    }\n",
    "    \n",
    "    # Store the metadata in the results list\n",
    "    results.append(metadata)\n",
    "\n",
    "# Save the results into a CSV file\n",
    "with open('travelphotos.csv', 'w', encoding='utf-8', newline='') as file:\n",
    "    fieldnames = ['title', 'score', 'author', 'created_date', 'url', 'num_comments']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "print('Results saved to travelphotos.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
